{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuyameng128/DL_study/blob/pytorch/chapter_deep-learning-computation/use-gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "618fd23a",
      "metadata": {
        "origin_pos": 0,
        "id": "618fd23a"
      },
      "source": [
        "# GPU\n",
        ":label:`sec_use_gpu`\n",
        "\n",
        "在 :numref:`tab_intro_decade`中，\n",
        "我们回顾了过去20年计算能力的快速增长。\n",
        "简而言之，自2000年以来，GPU性能每十年增长1000倍。\n",
        "\n",
        "本节，我们将讨论如何利用这种计算性能进行研究。\n",
        "首先是如何使用单个GPU，然后是如何使用多个GPU和多个服务器（具有多个GPU）。\n",
        "\n",
        "我们先看看如何使用单个NVIDIA GPU进行计算。\n",
        "首先，确保至少安装了一个NVIDIA GPU。\n",
        "然后，下载[NVIDIA驱动和CUDA](https://developer.nvidia.com/cuda-downloads)\n",
        "并按照提示设置适当的路径。\n",
        "当这些准备工作完成，就可以使用`nvidia-smi`命令来(**查看显卡信息。**)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "369d9baa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:58:06.499888Z",
          "iopub.status.busy": "2023-08-18T06:58:06.499324Z",
          "iopub.status.idle": "2023-08-18T06:58:06.859541Z",
          "shell.execute_reply": "2023-08-18T06:58:06.858210Z"
        },
        "origin_pos": 1,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "369d9baa",
        "outputId": "9ec907d9-db73-4655-9cb0-410d20a87a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct 31 08:12:22 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e1982b",
      "metadata": {
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "23e1982b"
      },
      "source": [
        "在PyTorch中，每个数组都有一个设备（device），\n",
        "我们通常将其称为环境（context）。\n",
        "默认情况下，所有变量和相关的计算都分配给CPU。\n",
        "有时环境可能是GPU。\n",
        "当我们跨多个服务器部署作业时，事情会变得更加棘手。\n",
        "通过智能地将数组分配给环境，\n",
        "我们可以最大限度地减少在设备之间传输数据的时间。\n",
        "例如，当在带有GPU的服务器上训练神经网络时，\n",
        "我们通常希望模型的参数在GPU上。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeacf63c",
      "metadata": {
        "origin_pos": 5,
        "id": "aeacf63c"
      },
      "source": [
        "要运行此部分中的程序，至少需要两个GPU。\n",
        "注意，对大多数桌面计算机来说，这可能是奢侈的，但在云中很容易获得。\n",
        "例如可以使用AWS EC2的多GPU实例。\n",
        "本书的其他章节大都不需要多个GPU，\n",
        "而本节只是为了展示数据如何在不同的设备之间传递。\n",
        "\n",
        "## [**计算设备**]\n",
        "\n",
        "我们可以指定用于存储和计算的设备，如CPU和GPU。\n",
        "默认情况下，张量是在内存中创建的，然后使用CPU计算它。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "872e46f0",
      "metadata": {
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "872e46f0"
      },
      "source": [
        "在PyTorch中，CPU和GPU可以用`torch.device('cpu')`\n",
        "和`torch.device('cuda')`表示。\n",
        "应该注意的是，`cpu`设备意味着所有物理CPU和内存，\n",
        "这意味着PyTorch的计算将尝试使用所有CPU核心。\n",
        "然而，`gpu`设备只代表一个卡和相应的显存。\n",
        "如果有多个GPU，我们使用`torch.device(f'cuda:{i}')`\n",
        "来表示第$i$块GPU（$i$从0开始）。\n",
        "另外，`cuda:0`和`cuda`是等价的。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9f69ad46",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:58:06.865430Z",
          "iopub.status.busy": "2023-08-18T06:58:06.864979Z",
          "iopub.status.idle": "2023-08-18T06:58:07.970615Z",
          "shell.execute_reply": "2023-08-18T06:58:07.969801Z"
        },
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f69ad46",
        "outputId": "99a77a17-18d2-4873-dfbb-6aea05a8374e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cpu'), device(type='cuda'), device(type='cuda', index=1))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.device('cpu'), torch.device('cuda'), torch.device('cuda:1')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "248784cc",
      "metadata": {
        "origin_pos": 13,
        "id": "248784cc"
      },
      "source": [
        "我们可以(**查询可用gpu的数量。**)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c29151b0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:58:07.974568Z",
          "iopub.status.busy": "2023-08-18T06:58:07.973917Z",
          "iopub.status.idle": "2023-08-18T06:58:07.979097Z",
          "shell.execute_reply": "2023-08-18T06:58:07.978337Z"
        },
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c29151b0",
        "outputId": "802b3f1c-094f-4d84-fe32-5dd4575687a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e1bc4a6",
      "metadata": {
        "origin_pos": 18,
        "id": "6e1bc4a6"
      },
      "source": [
        "现在我们定义了两个方便的函数，\n",
        "[**这两个函数允许我们在不存在所需所有GPU的情况下运行代码。**]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cda0ab76",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:58:07.983261Z",
          "iopub.status.busy": "2023-08-18T06:58:07.982604Z",
          "iopub.status.idle": "2023-08-18T06:58:07.990309Z",
          "shell.execute_reply": "2023-08-18T06:58:07.989541Z"
        },
        "origin_pos": 20,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cda0ab76",
        "outputId": "1029a102-aa65-40ac-f183-097245e9286e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0),\n",
              " device(type='cpu'),\n",
              " [device(type='cuda', index=0)])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "def try_gpu(i=0):\n",
        "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')\n",
        "\n",
        "def try_all_gpus():\n",
        "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]\"\"\"\n",
        "    devices = [torch.device(f'cuda:{i}')\n",
        "             for i in range(torch.cuda.device_count())]\n",
        "    return devices if devices else [torch.device('cpu')]\n",
        "\n",
        "try_gpu(), try_gpu(10), try_all_gpus()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "034b0d3b",
      "metadata": {
        "origin_pos": 23,
        "id": "034b0d3b"
      },
      "source": [
        "## 张量与GPU\n",
        "\n",
        "我们可以[**查询张量所在的设备。**]\n",
        "默认情况下，张量是在CPU上创建的。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f6ab0f26",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:58:07.994741Z",
          "iopub.status.busy": "2023-08-18T06:58:07.994126Z",
          "iopub.status.idle": "2023-08-18T06:58:07.999439Z",
          "shell.execute_reply": "2023-08-18T06:58:07.998673Z"
        },
        "origin_pos": 25,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6ab0f26",
        "outputId": "a82c5c34-9439-4a78-c6a0-2cf2af553212"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "x = torch.tensor([1, 2, 3])\n",
        "x.device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f39b0efa",
      "metadata": {
        "origin_pos": 28,
        "id": "f39b0efa"
      },
      "source": [
        "需要注意的是，无论何时我们要对多个项进行操作，\n",
        "它们都必须在同一个设备上。\n",
        "例如，如果我们对两个张量求和，\n",
        "我们需要确保两个张量都位于同一个设备上，\n",
        "否则框架将不知道在哪里存储结果，甚至不知道在哪里执行计算。\n",
        "\n",
        "### [**存储在GPU上**]\n",
        "\n",
        "有几种方法可以在GPU上存储张量。\n",
        "例如，我们可以在创建张量时指定存储设备。接\n",
        "下来，我们在第一个`gpu`上创建张量变量`X`。\n",
        "在GPU上创建的张量只消耗这个GPU的显存。\n",
        "我们可以使用`nvidia-smi`命令查看显存使用情况。\n",
        "一般来说，我们需要确保不创建超过GPU显存限制的数据。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a67dbf2f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:58:08.004162Z",
          "iopub.status.busy": "2023-08-18T06:58:08.003541Z",
          "iopub.status.idle": "2023-08-18T06:58:09.277879Z",
          "shell.execute_reply": "2023-08-18T06:58:09.277008Z"
        },
        "origin_pos": 30,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a67dbf2f",
        "outputId": "73d3d6c8-5e67-4ca6-bffc-50f1a4f75124"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X = torch.ones(2, 3, device=try_gpu())\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd17f6d7",
      "metadata": {
        "origin_pos": 33,
        "id": "dd17f6d7"
      },
      "source": [
        "假设我们至少有两个GPU，下面的代码将在(**第二个GPU上创建一个随机张量。**)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7c0d4a84",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:58:09.282814Z",
          "iopub.status.busy": "2023-08-18T06:58:09.282230Z",
          "iopub.status.idle": "2023-08-18T06:58:10.279046Z",
          "shell.execute_reply": "2023-08-18T06:58:10.278227Z"
        },
        "origin_pos": 35,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c0d4a84",
        "outputId": "0ca09e1f-663b-4678-f0cb-24ad5b64d752"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0325, 0.8547, 0.7604],\n",
              "        [0.4260, 0.7518, 0.4177]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "Y = torch.rand(2, 3, device=try_gpu(1))\n",
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71646fa2",
      "metadata": {
        "origin_pos": 38,
        "id": "71646fa2"
      },
      "source": [
        "### 复制\n",
        "\n",
        "如果我们[**要计算`X + Y`，我们需要决定在哪里执行这个操作**]。\n",
        "例如，如 :numref:`fig_copyto`所示，\n",
        "我们可以将`X`传输到第二个GPU并在那里执行操作。\n",
        "*不要*简单地`X`加上`Y`，因为这会导致异常，\n",
        "运行时引擎不知道该怎么做：它在同一设备上找不到数据会导致失败。\n",
        "由于`Y`位于第二个GPU上，所以我们需要将`X`移到那里，\n",
        "然后才能执行相加运算。\n",
        "\n",
        "![复制数据以在同一设备上执行操作](http://d2l.ai/_images/copyto.svg)\n",
        ":label:`fig_copyto`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "在GPU与GPU之间尤其是GPU与CPU之间挪动数据非常耗费时间"
      ],
      "metadata": {
        "id": "EljZZblQW4Cy"
      },
      "id": "EljZZblQW4Cy"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9e700cd2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:58:10.284097Z",
          "iopub.status.busy": "2023-08-18T06:58:10.283529Z",
          "iopub.status.idle": "2023-08-18T06:58:10.290795Z",
          "shell.execute_reply": "2023-08-18T06:58:10.290007Z"
        },
        "origin_pos": 40,
        "tab": [
          "pytorch"
        ],
        "id": "9e700cd2",
        "outputId": "8e781a49-70eb-4013-d80a-a6e11e401e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-045efdabb693>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "Z = X.cuda(1)\n",
        "print(X)\n",
        "print(Z)\n",
        "# 无法执行这段代码，我们只有一块GPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qoSPl1fqowSI"
      },
      "id": "qoSPl1fqowSI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f57eab12",
      "metadata": {
        "origin_pos": 42,
        "id": "f57eab12"
      },
      "source": [
        "[**现在数据在同一个GPU上（`Z`和`Y`都在），我们可以将它们相加。**]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.device"
      ],
      "metadata": {
        "id": "i8cLa0S8oxal",
        "outputId": "cf050acf-f4c1-498e-b781-b62048f9c068",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "i8cLa0S8oxal",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b2f04f35",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:58:10.295377Z",
          "iopub.status.busy": "2023-08-18T06:58:10.294845Z",
          "iopub.status.idle": "2023-08-18T06:58:10.301122Z",
          "shell.execute_reply": "2023-08-18T06:58:10.300297Z"
        },
        "origin_pos": 43,
        "tab": [
          "pytorch"
        ],
        "id": "b2f04f35",
        "outputId": "637056d9-ddf2-4377-b2e6-5df13d22e62d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e37447af6361>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "Y + Z"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9acbe573",
      "metadata": {
        "origin_pos": 45,
        "tab": [
          "pytorch"
        ],
        "id": "9acbe573"
      },
      "source": [
        "假设变量`Z`已经存在于第二个GPU上。\n",
        "如果我们还是调用`Z.cuda(1)`会发生什么？\n",
        "它将返回`Z`，而不会复制并分配新内存。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b95aa1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:58:10.305143Z",
          "iopub.status.busy": "2023-08-18T06:58:10.304592Z",
          "iopub.status.idle": "2023-08-18T06:58:10.309707Z",
          "shell.execute_reply": "2023-08-18T06:58:10.308894Z"
        },
        "origin_pos": 48,
        "tab": [
          "pytorch"
        ],
        "id": "d6b95aa1"
      },
      "outputs": [],
      "source": [
        "Z.cuda(1) is Z"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35568455",
      "metadata": {
        "origin_pos": 50,
        "id": "35568455"
      },
      "source": [
        "### 旁注\n",
        "\n",
        "人们使用GPU来进行机器学习，因为单个GPU相对运行速度快。\n",
        "但是在设备（CPU、GPU和其他机器）之间传输数据比计算慢得多。\n",
        "这也使得并行化变得更加困难，因为我们必须等待数据被发送（或者接收），\n",
        "然后才能继续进行更多的操作。\n",
        "这就是为什么拷贝操作要格外小心。\n",
        "根据经验，多个小操作比一个大操作糟糕得多。\n",
        "此外，一次执行几个操作比代码中散布的许多单个操作要好得多。\n",
        "如果一个设备必须等待另一个设备才能执行其他操作，\n",
        "那么这样的操作可能会阻塞。\n",
        "这有点像排队订购咖啡，而不像通过电话预先订购：\n",
        "当客人到店的时候，咖啡已经准备好了。\n",
        "\n",
        "最后，当我们打印张量或将张量转换为NumPy格式时，\n",
        "如果数据不在内存中，框架会首先将其复制到内存中，\n",
        "这会导致额外的传输开销。\n",
        "更糟糕的是，它现在受制于全局解释器锁，使得一切都得等待Python完成。\n",
        "\n",
        "## [**神经网络与GPU**]\n",
        "\n",
        "类似地，神经网络模型可以指定设备。\n",
        "下面的代码将模型参数放在GPU上。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "587af904",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:58:10.313163Z",
          "iopub.status.busy": "2023-08-18T06:58:10.312623Z",
          "iopub.status.idle": "2023-08-18T06:58:10.336351Z",
          "shell.execute_reply": "2023-08-18T06:58:10.335568Z"
        },
        "origin_pos": 52,
        "tab": [
          "pytorch"
        ],
        "id": "587af904"
      },
      "outputs": [],
      "source": [
        "net = nn.Sequential(nn.Linear(3, 1))\n",
        "net = net.to(device=try_gpu())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a834a04c",
      "metadata": {
        "origin_pos": 55,
        "id": "a834a04c"
      },
      "source": [
        "在接下来的几章中，\n",
        "我们将看到更多关于如何在GPU上运行模型的例子，\n",
        "因为它们将变得更加计算密集。\n",
        "\n",
        "当输入为GPU上的张量时，模型将在同一GPU上计算结果。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "955f7f67",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:58:10.340989Z",
          "iopub.status.busy": "2023-08-18T06:58:10.340312Z",
          "iopub.status.idle": "2023-08-18T06:58:10.930969Z",
          "shell.execute_reply": "2023-08-18T06:58:10.930143Z"
        },
        "origin_pos": 56,
        "tab": [
          "pytorch"
        ],
        "id": "955f7f67"
      },
      "outputs": [],
      "source": [
        "net(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb9f9aef",
      "metadata": {
        "origin_pos": 57,
        "id": "fb9f9aef"
      },
      "source": [
        "让我们(**确认模型参数存储在同一个GPU上。**)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd727993",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T06:58:10.935087Z",
          "iopub.status.busy": "2023-08-18T06:58:10.934497Z",
          "iopub.status.idle": "2023-08-18T06:58:10.939740Z",
          "shell.execute_reply": "2023-08-18T06:58:10.938974Z"
        },
        "origin_pos": 59,
        "tab": [
          "pytorch"
        ],
        "id": "bd727993"
      },
      "outputs": [],
      "source": [
        "net[0].weight.data.device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf1bf3b2",
      "metadata": {
        "origin_pos": 62,
        "id": "cf1bf3b2"
      },
      "source": [
        "总之，只要所有的数据和参数都在同一个设备上，\n",
        "我们就可以有效地学习模型。\n",
        "在下面的章节中，我们将看到几个这样的例子。\n",
        "\n",
        "## 小结\n",
        "\n",
        "* 我们可以指定用于存储和计算的设备，例如CPU或GPU。默认情况下，数据在主内存中创建，然后使用CPU进行计算。\n",
        "* 深度学习框架要求计算的所有输入数据都在同一设备上，无论是CPU还是GPU。\n",
        "* 不经意地移动数据可能会显著降低性能。一个典型的错误如下：计算GPU上每个小批量的损失，并在命令行中将其报告给用户（或将其记录在NumPy `ndarray`中）时，将触发全局解释器锁，从而使所有GPU阻塞。最好是为GPU内部的日志分配内存，并且只移动较大的日志。\n",
        "\n",
        "## 练习\n",
        "\n",
        "1. 尝试一个计算量更大的任务，比如大矩阵的乘法，看看CPU和GPU之间的速度差异。再试一个计算量很小的任务呢？\n",
        "1. 我们应该如何在GPU上读写模型参数？\n",
        "1. 测量计算1000个$100 \\times 100$矩阵的矩阵乘法所需的时间，并记录输出矩阵的Frobenius范数，一次记录一个结果，而不是在GPU上保存日志并仅传输最终结果。\n",
        "1. 测量同时在两个GPU上执行两个矩阵乘法与在一个GPU上按顺序执行两个矩阵乘法所需的时间。提示：应该看到近乎线性的缩放。\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.尝试一个计算量更大的任务，比如大矩阵的乘法，看看CPU和GPU之间的速度差异\n",
        "import torch\n",
        "import time\n",
        "\n",
        "def matrix_multiply(size):\n",
        "  cpu_device=torch.device('cpu')\n",
        "  a_cpu=torch.randn(size,size,device=cpu_device)\n",
        "  b_cpu=torch.randn(size,size,device=cpu_device)\n",
        "\n",
        "  start_time=time.time()\n",
        "  c_cpu=torch.mm(a_cpu,b_cpu)\n",
        "  cpu_time=time.time()-start_time\n",
        "  print(f'CPU time:{cpu_time:.4f} seconds')\n",
        "\n",
        "  gpu_device=try_gpu()\n",
        "  a_gpu=a_cpu.to(gpu_device)\n",
        "  b_gpu=b_cpu.to(gpu_device)\n",
        "\n",
        "  g_start_time=time.time()\n",
        "  c_gpu=torch.mm(a_gpu,b_gpu)\n",
        "  gpu_time=time.time()-g_start_time\n",
        "  print(f'GPU time:{gpu_time:.4f} seconds')\n",
        "\n",
        "\n",
        "matrix_size=1000\n",
        "matrix_multiply(matrix_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmOX4OU8iUoz",
        "outputId": "252f1ae9-582f-4e0b-ad5a-d40119e242df"
      },
      "id": "LmOX4OU8iUoz",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU time:0.0162 seconds\n",
            "GPU time:0.0001 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_multiply(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a75cjTzQiYKQ",
        "outputId": "f76a08ab-5588-472f-bf4c-fd9378b9cfd2"
      },
      "id": "a75cjTzQiYKQ",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU time:0.0038 seconds\n",
            "GPU time:0.0002 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.我们应该如何在GPU上读写模型参数？"
      ],
      "metadata": {
        "id": "LzT06gjry6pC"
      },
      "id": "LzT06gjry6pC"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.fc = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "device=try_gpu()\n",
        "model=SimpleModel().to(device)\n",
        "# 用net.to()方法将模型移动到GPU，再按之前的方法读写参数\n",
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRXcq4jey86j",
        "outputId": "a41222b0-e2aa-4634-9ef6-d024b4e6d5ed"
      },
      "id": "NRXcq4jey86j",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('fc.weight',\n",
              "              tensor([[-0.2968,  0.0877,  0.1394,  0.0528,  0.2422, -0.0676, -0.1243,  0.2016,\n",
              "                       -0.0898,  0.1138],\n",
              "                      [ 0.2383, -0.2227,  0.1431, -0.1367, -0.0087,  0.2061,  0.2853,  0.2295,\n",
              "                        0.2765, -0.2869]], device='cuda:0')),\n",
              "             ('fc.bias', tensor([ 0.0739, -0.1627], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.测量计算1000个 100×100 矩阵的矩阵乘法所需的时间，并记录输出矩阵的Frobenius范数，一次记录一个结果，而不是在GPU上保存日志并仅传输最终结果"
      ],
      "metadata": {
        "id": "sx32_9xMn5yD"
      },
      "id": "sx32_9xMn5yD"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n"
      ],
      "metadata": {
        "id": "Lpfc1TzOpNIw"
      },
      "id": "Lpfc1TzOpNIw",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mul_device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "matrices=[torch.rand(100,100).to(mul_device) for i in range(1000)]\n",
        "\n",
        "# 实验一：只计算乘法\n",
        "start_time_1=time.time()\n",
        "for i in range(1000):\n",
        "  result=torch.mm(matrices[i],matrices[i].t())\n",
        "  Frobenius_norm=torch.norm(result,p='fro')\n",
        "end_time_1=time.time()\n",
        "\n",
        "# 实验二：一一打印每次结果的Frobenius范数\n",
        "start_time_2=time.time()\n",
        "for i in range(1000):\n",
        "  result=torch.mm(matrices[i],matrices[i].t())\n",
        "  Frobenius_norm=torch.norm(result,p='fro')\n",
        "  print(Frobenius_norm)\n",
        "end_time_2=time.time()\n",
        "\n",
        "print(f\"实验一消耗时间：{end_time_1-start_time_1}，  实验二消耗时间：{end_time_2-start_time_2}\")"
      ],
      "metadata": {
        "id": "6pk06SYi4Ji2",
        "outputId": "d4ce5f9e-cbe1-416b-c646-f6486dfaf5bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6pk06SYi4Ji2",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2462.6047, device='cuda:0')\n",
            "tensor(2522.9258, device='cuda:0')\n",
            "tensor(2535.0625, device='cuda:0')\n",
            "tensor(2524.0518, device='cuda:0')\n",
            "tensor(2519.1790, device='cuda:0')\n",
            "tensor(2563.7136, device='cuda:0')\n",
            "tensor(2507.6929, device='cuda:0')\n",
            "tensor(2551.9397, device='cuda:0')\n",
            "tensor(2507.5613, device='cuda:0')\n",
            "tensor(2503.3499, device='cuda:0')\n",
            "tensor(2553.0317, device='cuda:0')\n",
            "tensor(2528.0806, device='cuda:0')\n",
            "tensor(2497.5273, device='cuda:0')\n",
            "tensor(2517.0442, device='cuda:0')\n",
            "tensor(2524.6633, device='cuda:0')\n",
            "tensor(2547.2561, device='cuda:0')\n",
            "tensor(2445.5371, device='cuda:0')\n",
            "tensor(2533.9839, device='cuda:0')\n",
            "tensor(2532.8984, device='cuda:0')\n",
            "tensor(2530.2375, device='cuda:0')\n",
            "tensor(2485.8186, device='cuda:0')\n",
            "tensor(2465.8994, device='cuda:0')\n",
            "tensor(2533.8938, device='cuda:0')\n",
            "tensor(2536.1909, device='cuda:0')\n",
            "tensor(2533.9607, device='cuda:0')\n",
            "tensor(2487.1018, device='cuda:0')\n",
            "tensor(2519.0017, device='cuda:0')\n",
            "tensor(2467.4954, device='cuda:0')\n",
            "tensor(2498.1775, device='cuda:0')\n",
            "tensor(2575.6218, device='cuda:0')\n",
            "tensor(2531.3699, device='cuda:0')\n",
            "tensor(2529.0146, device='cuda:0')\n",
            "tensor(2531.7302, device='cuda:0')\n",
            "tensor(2546.9082, device='cuda:0')\n",
            "tensor(2562.8813, device='cuda:0')\n",
            "tensor(2551.8040, device='cuda:0')\n",
            "tensor(2520.0273, device='cuda:0')\n",
            "tensor(2482.0620, device='cuda:0')\n",
            "tensor(2525.6013, device='cuda:0')\n",
            "tensor(2466.7002, device='cuda:0')\n",
            "tensor(2481.7527, device='cuda:0')\n",
            "tensor(2502.7783, device='cuda:0')\n",
            "tensor(2547.0300, device='cuda:0')\n",
            "tensor(2483.4226, device='cuda:0')\n",
            "tensor(2514.9546, device='cuda:0')\n",
            "tensor(2500.1389, device='cuda:0')\n",
            "tensor(2456.6643, device='cuda:0')\n",
            "tensor(2549.5476, device='cuda:0')\n",
            "tensor(2516.8115, device='cuda:0')\n",
            "tensor(2501.0725, device='cuda:0')\n",
            "tensor(2492.3491, device='cuda:0')\n",
            "tensor(2485.0303, device='cuda:0')\n",
            "tensor(2501.0190, device='cuda:0')\n",
            "tensor(2546.7649, device='cuda:0')\n",
            "tensor(2505.4717, device='cuda:0')\n",
            "tensor(2525.7063, device='cuda:0')\n",
            "tensor(2551.6069, device='cuda:0')\n",
            "tensor(2512.0913, device='cuda:0')\n",
            "tensor(2519.7947, device='cuda:0')\n",
            "tensor(2554.0742, device='cuda:0')\n",
            "tensor(2510.2844, device='cuda:0')\n",
            "tensor(2479.5317, device='cuda:0')\n",
            "tensor(2501.2063, device='cuda:0')\n",
            "tensor(2494.5564, device='cuda:0')\n",
            "tensor(2529.6765, device='cuda:0')\n",
            "tensor(2555.4395, device='cuda:0')\n",
            "tensor(2533.2168, device='cuda:0')\n",
            "tensor(2507.7500, device='cuda:0')\n",
            "tensor(2486.8347, device='cuda:0')\n",
            "tensor(2514.2588, device='cuda:0')\n",
            "tensor(2482.8777, device='cuda:0')\n",
            "tensor(2569.8972, device='cuda:0')\n",
            "tensor(2503.2336, device='cuda:0')\n",
            "tensor(2506.2942, device='cuda:0')\n",
            "tensor(2546.9998, device='cuda:0')\n",
            "tensor(2470.7209, device='cuda:0')\n",
            "tensor(2483.3479, device='cuda:0')\n",
            "tensor(2510.1792, device='cuda:0')\n",
            "tensor(2495.5940, device='cuda:0')\n",
            "tensor(2437.1458, device='cuda:0')\n",
            "tensor(2507.1504, device='cuda:0')\n",
            "tensor(2519.9529, device='cuda:0')\n",
            "tensor(2476.5569, device='cuda:0')\n",
            "tensor(2524.5732, device='cuda:0')\n",
            "tensor(2554.7666, device='cuda:0')\n",
            "tensor(2538.9011, device='cuda:0')\n",
            "tensor(2512.1074, device='cuda:0')\n",
            "tensor(2528.0125, device='cuda:0')\n",
            "tensor(2491.5195, device='cuda:0')\n",
            "tensor(2489.5935, device='cuda:0')\n",
            "tensor(2517.7053, device='cuda:0')\n",
            "tensor(2513.6887, device='cuda:0')\n",
            "tensor(2521.7737, device='cuda:0')\n",
            "tensor(2560.8594, device='cuda:0')\n",
            "tensor(2501.6484, device='cuda:0')\n",
            "tensor(2515.2634, device='cuda:0')\n",
            "tensor(2533.9473, device='cuda:0')\n",
            "tensor(2509.3994, device='cuda:0')\n",
            "tensor(2519.7412, device='cuda:0')\n",
            "tensor(2574.1262, device='cuda:0')\n",
            "tensor(2624.6433, device='cuda:0')\n",
            "tensor(2530.2422, device='cuda:0')\n",
            "tensor(2566.5798, device='cuda:0')\n",
            "tensor(2512.9104, device='cuda:0')\n",
            "tensor(2585.9448, device='cuda:0')\n",
            "tensor(2554.0271, device='cuda:0')\n",
            "tensor(2521.2881, device='cuda:0')\n",
            "tensor(2536.3396, device='cuda:0')\n",
            "tensor(2511.5789, device='cuda:0')\n",
            "tensor(2437.3706, device='cuda:0')\n",
            "tensor(2522.2195, device='cuda:0')\n",
            "tensor(2500.5229, device='cuda:0')\n",
            "tensor(2545.4138, device='cuda:0')\n",
            "tensor(2539.7634, device='cuda:0')\n",
            "tensor(2492.3967, device='cuda:0')\n",
            "tensor(2496.5591, device='cuda:0')\n",
            "tensor(2506.5403, device='cuda:0')\n",
            "tensor(2558.9336, device='cuda:0')\n",
            "tensor(2526.3770, device='cuda:0')\n",
            "tensor(2502.1145, device='cuda:0')\n",
            "tensor(2511.9451, device='cuda:0')\n",
            "tensor(2526.4966, device='cuda:0')\n",
            "tensor(2560.7073, device='cuda:0')\n",
            "tensor(2520.1875, device='cuda:0')\n",
            "tensor(2512.6619, device='cuda:0')\n",
            "tensor(2516.4597, device='cuda:0')\n",
            "tensor(2519.3081, device='cuda:0')\n",
            "tensor(2585.3687, device='cuda:0')\n",
            "tensor(2543.0989, device='cuda:0')\n",
            "tensor(2559.4529, device='cuda:0')\n",
            "tensor(2515.3259, device='cuda:0')\n",
            "tensor(2527.3496, device='cuda:0')\n",
            "tensor(2536.1863, device='cuda:0')\n",
            "tensor(2559.7654, device='cuda:0')\n",
            "tensor(2516.0068, device='cuda:0')\n",
            "tensor(2525.1240, device='cuda:0')\n",
            "tensor(2496.5354, device='cuda:0')\n",
            "tensor(2516.6689, device='cuda:0')\n",
            "tensor(2525.1833, device='cuda:0')\n",
            "tensor(2505.1250, device='cuda:0')\n",
            "tensor(2579.8596, device='cuda:0')\n",
            "tensor(2537.5024, device='cuda:0')\n",
            "tensor(2558.4553, device='cuda:0')\n",
            "tensor(2541.7964, device='cuda:0')\n",
            "tensor(2511.1086, device='cuda:0')\n",
            "tensor(2595.8701, device='cuda:0')\n",
            "tensor(2497.2205, device='cuda:0')\n",
            "tensor(2499.0039, device='cuda:0')\n",
            "tensor(2562.6326, device='cuda:0')\n",
            "tensor(2503.4902, device='cuda:0')\n",
            "tensor(2490.0693, device='cuda:0')\n",
            "tensor(2485.6172, device='cuda:0')\n",
            "tensor(2476.4556, device='cuda:0')\n",
            "tensor(2514.4802, device='cuda:0')\n",
            "tensor(2516.3450, device='cuda:0')\n",
            "tensor(2509.1089, device='cuda:0')\n",
            "tensor(2566.4749, device='cuda:0')\n",
            "tensor(2507.7549, device='cuda:0')\n",
            "tensor(2511.3250, device='cuda:0')\n",
            "tensor(2531.8977, device='cuda:0')\n",
            "tensor(2603.5378, device='cuda:0')\n",
            "tensor(2534.3616, device='cuda:0')\n",
            "tensor(2535.3396, device='cuda:0')\n",
            "tensor(2507.3020, device='cuda:0')\n",
            "tensor(2532.0654, device='cuda:0')\n",
            "tensor(2531.8164, device='cuda:0')\n",
            "tensor(2525.4431, device='cuda:0')\n",
            "tensor(2501.7222, device='cuda:0')\n",
            "tensor(2475.9829, device='cuda:0')\n",
            "tensor(2459.5242, device='cuda:0')\n",
            "tensor(2532.6472, device='cuda:0')\n",
            "tensor(2465.5852, device='cuda:0')\n",
            "tensor(2536.1809, device='cuda:0')\n",
            "tensor(2513.2502, device='cuda:0')\n",
            "tensor(2515.3994, device='cuda:0')\n",
            "tensor(2526.6584, device='cuda:0')\n",
            "tensor(2507.5884, device='cuda:0')\n",
            "tensor(2498.0916, device='cuda:0')\n",
            "tensor(2511.8318, device='cuda:0')\n",
            "tensor(2488.7566, device='cuda:0')\n",
            "tensor(2536.5513, device='cuda:0')\n",
            "tensor(2558.1353, device='cuda:0')\n",
            "tensor(2562.5867, device='cuda:0')\n",
            "tensor(2524.7261, device='cuda:0')\n",
            "tensor(2550.3018, device='cuda:0')\n",
            "tensor(2556.5417, device='cuda:0')\n",
            "tensor(2500.5671, device='cuda:0')\n",
            "tensor(2508.3472, device='cuda:0')\n",
            "tensor(2450.6531, device='cuda:0')\n",
            "tensor(2528.3025, device='cuda:0')\n",
            "tensor(2533.7534, device='cuda:0')\n",
            "tensor(2494.7571, device='cuda:0')\n",
            "tensor(2529.8403, device='cuda:0')\n",
            "tensor(2544.5618, device='cuda:0')\n",
            "tensor(2548.6875, device='cuda:0')\n",
            "tensor(2517.0229, device='cuda:0')\n",
            "tensor(2538.0842, device='cuda:0')\n",
            "tensor(2497.0046, device='cuda:0')\n",
            "tensor(2485.8406, device='cuda:0')\n",
            "tensor(2545.0042, device='cuda:0')\n",
            "tensor(2531.2424, device='cuda:0')\n",
            "tensor(2573.5430, device='cuda:0')\n",
            "tensor(2491.7966, device='cuda:0')\n",
            "tensor(2537.2024, device='cuda:0')\n",
            "tensor(2499.6868, device='cuda:0')\n",
            "tensor(2478.4399, device='cuda:0')\n",
            "tensor(2499.3391, device='cuda:0')\n",
            "tensor(2500.5942, device='cuda:0')\n",
            "tensor(2550.4946, device='cuda:0')\n",
            "tensor(2478.1069, device='cuda:0')\n",
            "tensor(2521.9751, device='cuda:0')\n",
            "tensor(2503.1301, device='cuda:0')\n",
            "tensor(2567.7666, device='cuda:0')\n",
            "tensor(2519.5193, device='cuda:0')\n",
            "tensor(2520.1733, device='cuda:0')\n",
            "tensor(2496.8376, device='cuda:0')\n",
            "tensor(2539.0776, device='cuda:0')\n",
            "tensor(2547.8032, device='cuda:0')\n",
            "tensor(2530.9587, device='cuda:0')\n",
            "tensor(2513.7114, device='cuda:0')\n",
            "tensor(2490.2957, device='cuda:0')\n",
            "tensor(2551.7449, device='cuda:0')\n",
            "tensor(2547.8816, device='cuda:0')\n",
            "tensor(2496.8601, device='cuda:0')\n",
            "tensor(2564.0818, device='cuda:0')\n",
            "tensor(2517.9355, device='cuda:0')\n",
            "tensor(2456.9543, device='cuda:0')\n",
            "tensor(2509.2212, device='cuda:0')\n",
            "tensor(2510.9167, device='cuda:0')\n",
            "tensor(2537.2415, device='cuda:0')\n",
            "tensor(2505.6121, device='cuda:0')\n",
            "tensor(2514.0444, device='cuda:0')\n",
            "tensor(2509.4216, device='cuda:0')\n",
            "tensor(2547.2468, device='cuda:0')\n",
            "tensor(2553.7422, device='cuda:0')\n",
            "tensor(2509.8987, device='cuda:0')\n",
            "tensor(2601.6917, device='cuda:0')\n",
            "tensor(2588.1304, device='cuda:0')\n",
            "tensor(2526.1475, device='cuda:0')\n",
            "tensor(2548.4375, device='cuda:0')\n",
            "tensor(2490.6396, device='cuda:0')\n",
            "tensor(2499.4314, device='cuda:0')\n",
            "tensor(2527.3132, device='cuda:0')\n",
            "tensor(2510.0891, device='cuda:0')\n",
            "tensor(2491.3625, device='cuda:0')\n",
            "tensor(2550.1206, device='cuda:0')\n",
            "tensor(2560.7776, device='cuda:0')\n",
            "tensor(2509.8918, device='cuda:0')\n",
            "tensor(2572.4634, device='cuda:0')\n",
            "tensor(2539.2720, device='cuda:0')\n",
            "tensor(2547.8704, device='cuda:0')\n",
            "tensor(2552.8123, device='cuda:0')\n",
            "tensor(2508.4670, device='cuda:0')\n",
            "tensor(2483.3286, device='cuda:0')\n",
            "tensor(2516.1357, device='cuda:0')\n",
            "tensor(2512.0259, device='cuda:0')\n",
            "tensor(2571.2297, device='cuda:0')\n",
            "tensor(2490.9841, device='cuda:0')\n",
            "tensor(2493.7610, device='cuda:0')\n",
            "tensor(2525.7266, device='cuda:0')\n",
            "tensor(2536.0427, device='cuda:0')\n",
            "tensor(2525.7366, device='cuda:0')\n",
            "tensor(2468.2578, device='cuda:0')\n",
            "tensor(2516.2537, device='cuda:0')\n",
            "tensor(2524.0308, device='cuda:0')\n",
            "tensor(2596.5083, device='cuda:0')\n",
            "tensor(2533.7444, device='cuda:0')\n",
            "tensor(2539.3257, device='cuda:0')\n",
            "tensor(2551.6875, device='cuda:0')\n",
            "tensor(2509.9304, device='cuda:0')\n",
            "tensor(2521.9478, device='cuda:0')\n",
            "tensor(2514.5554, device='cuda:0')\n",
            "tensor(2493.6450, device='cuda:0')\n",
            "tensor(2544.8853, device='cuda:0')\n",
            "tensor(2532.9077, device='cuda:0')\n",
            "tensor(2575.5811, device='cuda:0')\n",
            "tensor(2510.4067, device='cuda:0')\n",
            "tensor(2561.9146, device='cuda:0')\n",
            "tensor(2474.3066, device='cuda:0')\n",
            "tensor(2550.4351, device='cuda:0')\n",
            "tensor(2481.5759, device='cuda:0')\n",
            "tensor(2516.0908, device='cuda:0')\n",
            "tensor(2499.0234, device='cuda:0')\n",
            "tensor(2534.2361, device='cuda:0')\n",
            "tensor(2524.6284, device='cuda:0')\n",
            "tensor(2536.2239, device='cuda:0')\n",
            "tensor(2523.7703, device='cuda:0')\n",
            "tensor(2560.7434, device='cuda:0')\n",
            "tensor(2476.3708, device='cuda:0')\n",
            "tensor(2515.2725, device='cuda:0')\n",
            "tensor(2498.2871, device='cuda:0')\n",
            "tensor(2521.9858, device='cuda:0')\n",
            "tensor(2569.8152, device='cuda:0')\n",
            "tensor(2566.1394, device='cuda:0')\n",
            "tensor(2512.7654, device='cuda:0')\n",
            "tensor(2543.3674, device='cuda:0')\n",
            "tensor(2514.3037, device='cuda:0')\n",
            "tensor(2469.0938, device='cuda:0')\n",
            "tensor(2562.4316, device='cuda:0')\n",
            "tensor(2514.8970, device='cuda:0')\n",
            "tensor(2559.9343, device='cuda:0')\n",
            "tensor(2536.8823, device='cuda:0')\n",
            "tensor(2539.3894, device='cuda:0')\n",
            "tensor(2521.7969, device='cuda:0')\n",
            "tensor(2528.3738, device='cuda:0')\n",
            "tensor(2471.0637, device='cuda:0')\n",
            "tensor(2534.5107, device='cuda:0')\n",
            "tensor(2517.4321, device='cuda:0')\n",
            "tensor(2541.8943, device='cuda:0')\n",
            "tensor(2541.8059, device='cuda:0')\n",
            "tensor(2553.0601, device='cuda:0')\n",
            "tensor(2420.0342, device='cuda:0')\n",
            "tensor(2550.7224, device='cuda:0')\n",
            "tensor(2533.5713, device='cuda:0')\n",
            "tensor(2495.1555, device='cuda:0')\n",
            "tensor(2560.6204, device='cuda:0')\n",
            "tensor(2580.3521, device='cuda:0')\n",
            "tensor(2573.5254, device='cuda:0')\n",
            "tensor(2543.3398, device='cuda:0')\n",
            "tensor(2507.0061, device='cuda:0')\n",
            "tensor(2548.0400, device='cuda:0')\n",
            "tensor(2486.0337, device='cuda:0')\n",
            "tensor(2492.4497, device='cuda:0')\n",
            "tensor(2541.3994, device='cuda:0')\n",
            "tensor(2518.9480, device='cuda:0')\n",
            "tensor(2497.8110, device='cuda:0')\n",
            "tensor(2491.5796, device='cuda:0')\n",
            "tensor(2562.9763, device='cuda:0')\n",
            "tensor(2464.1323, device='cuda:0')\n",
            "tensor(2517.7505, device='cuda:0')\n",
            "tensor(2527.2937, device='cuda:0')\n",
            "tensor(2458.1042, device='cuda:0')\n",
            "tensor(2504.2688, device='cuda:0')\n",
            "tensor(2479.4026, device='cuda:0')\n",
            "tensor(2523.4790, device='cuda:0')\n",
            "tensor(2520.5413, device='cuda:0')\n",
            "tensor(2497.1833, device='cuda:0')\n",
            "tensor(2533.2449, device='cuda:0')\n",
            "tensor(2511.1021, device='cuda:0')\n",
            "tensor(2542.0933, device='cuda:0')\n",
            "tensor(2510.0713, device='cuda:0')\n",
            "tensor(2502.8455, device='cuda:0')\n",
            "tensor(2506.7139, device='cuda:0')\n",
            "tensor(2500.3130, device='cuda:0')\n",
            "tensor(2487.3379, device='cuda:0')\n",
            "tensor(2536.6475, device='cuda:0')\n",
            "tensor(2459.1223, device='cuda:0')\n",
            "tensor(2515.9426, device='cuda:0')\n",
            "tensor(2494.6436, device='cuda:0')\n",
            "tensor(2539.2490, device='cuda:0')\n",
            "tensor(2496.1365, device='cuda:0')\n",
            "tensor(2521.7761, device='cuda:0')\n",
            "tensor(2561.6428, device='cuda:0')\n",
            "tensor(2557.7312, device='cuda:0')\n",
            "tensor(2538.6228, device='cuda:0')\n",
            "tensor(2528.1484, device='cuda:0')\n",
            "tensor(2536.1404, device='cuda:0')\n",
            "tensor(2479.3704, device='cuda:0')\n",
            "tensor(2519.5215, device='cuda:0')\n",
            "tensor(2506.7388, device='cuda:0')\n",
            "tensor(2468.7300, device='cuda:0')\n",
            "tensor(2508.2410, device='cuda:0')\n",
            "tensor(2531.2070, device='cuda:0')\n",
            "tensor(2501.3977, device='cuda:0')\n",
            "tensor(2539.4839, device='cuda:0')\n",
            "tensor(2532.0735, device='cuda:0')\n",
            "tensor(2541.7791, device='cuda:0')\n",
            "tensor(2509.3071, device='cuda:0')\n",
            "tensor(2478.4097, device='cuda:0')\n",
            "tensor(2495.8694, device='cuda:0')\n",
            "tensor(2500.6194, device='cuda:0')\n",
            "tensor(2529.0115, device='cuda:0')\n",
            "tensor(2517.8845, device='cuda:0')\n",
            "tensor(2520.1042, device='cuda:0')\n",
            "tensor(2516.8149, device='cuda:0')\n",
            "tensor(2480.8418, device='cuda:0')\n",
            "tensor(2483.8530, device='cuda:0')\n",
            "tensor(2539.7847, device='cuda:0')\n",
            "tensor(2537.6443, device='cuda:0')\n",
            "tensor(2519.2859, device='cuda:0')\n",
            "tensor(2524.9023, device='cuda:0')\n",
            "tensor(2520.7915, device='cuda:0')\n",
            "tensor(2526.0564, device='cuda:0')\n",
            "tensor(2511.6794, device='cuda:0')\n",
            "tensor(2534.5300, device='cuda:0')\n",
            "tensor(2453.9939, device='cuda:0')\n",
            "tensor(2520.4241, device='cuda:0')\n",
            "tensor(2518.9541, device='cuda:0')\n",
            "tensor(2527.4414, device='cuda:0')\n",
            "tensor(2546.6003, device='cuda:0')\n",
            "tensor(2608.7700, device='cuda:0')\n",
            "tensor(2495.9636, device='cuda:0')\n",
            "tensor(2500.5774, device='cuda:0')\n",
            "tensor(2562.9150, device='cuda:0')\n",
            "tensor(2515.1992, device='cuda:0')\n",
            "tensor(2526.2483, device='cuda:0')\n",
            "tensor(2530.6982, device='cuda:0')\n",
            "tensor(2447.6230, device='cuda:0')\n",
            "tensor(2538.0383, device='cuda:0')\n",
            "tensor(2496.5742, device='cuda:0')\n",
            "tensor(2551.5488, device='cuda:0')\n",
            "tensor(2534.8323, device='cuda:0')\n",
            "tensor(2584.9343, device='cuda:0')\n",
            "tensor(2467.5056, device='cuda:0')\n",
            "tensor(2511.7375, device='cuda:0')\n",
            "tensor(2489.2556, device='cuda:0')\n",
            "tensor(2549.4766, device='cuda:0')\n",
            "tensor(2550.4739, device='cuda:0')\n",
            "tensor(2551.1699, device='cuda:0')\n",
            "tensor(2517.3640, device='cuda:0')\n",
            "tensor(2525.6196, device='cuda:0')\n",
            "tensor(2523.7839, device='cuda:0')\n",
            "tensor(2474.8379, device='cuda:0')\n",
            "tensor(2564.9436, device='cuda:0')\n",
            "tensor(2500.7046, device='cuda:0')\n",
            "tensor(2482.6555, device='cuda:0')\n",
            "tensor(2514.0457, device='cuda:0')\n",
            "tensor(2509.3918, device='cuda:0')\n",
            "tensor(2510.7683, device='cuda:0')\n",
            "tensor(2512.0732, device='cuda:0')\n",
            "tensor(2536.9263, device='cuda:0')\n",
            "tensor(2539.2385, device='cuda:0')\n",
            "tensor(2506.6279, device='cuda:0')\n",
            "tensor(2561.7966, device='cuda:0')\n",
            "tensor(2503.6255, device='cuda:0')\n",
            "tensor(2571.2263, device='cuda:0')\n",
            "tensor(2516.4692, device='cuda:0')\n",
            "tensor(2530.0789, device='cuda:0')\n",
            "tensor(2501.9202, device='cuda:0')\n",
            "tensor(2452.2036, device='cuda:0')\n",
            "tensor(2508.1978, device='cuda:0')\n",
            "tensor(2575.3718, device='cuda:0')\n",
            "tensor(2526.7346, device='cuda:0')\n",
            "tensor(2496.5449, device='cuda:0')\n",
            "tensor(2554.1221, device='cuda:0')\n",
            "tensor(2543.7791, device='cuda:0')\n",
            "tensor(2481.4634, device='cuda:0')\n",
            "tensor(2508.5122, device='cuda:0')\n",
            "tensor(2484.9275, device='cuda:0')\n",
            "tensor(2529.5103, device='cuda:0')\n",
            "tensor(2517.3525, device='cuda:0')\n",
            "tensor(2492.3418, device='cuda:0')\n",
            "tensor(2533.6924, device='cuda:0')\n",
            "tensor(2562.6096, device='cuda:0')\n",
            "tensor(2499.3301, device='cuda:0')\n",
            "tensor(2545.8386, device='cuda:0')\n",
            "tensor(2544.3381, device='cuda:0')\n",
            "tensor(2513.0720, device='cuda:0')\n",
            "tensor(2507.8501, device='cuda:0')\n",
            "tensor(2547.0491, device='cuda:0')\n",
            "tensor(2552.1025, device='cuda:0')\n",
            "tensor(2535.4265, device='cuda:0')\n",
            "tensor(2546.4060, device='cuda:0')\n",
            "tensor(2507.4741, device='cuda:0')\n",
            "tensor(2536.3521, device='cuda:0')\n",
            "tensor(2565.1802, device='cuda:0')\n",
            "tensor(2558.4089, device='cuda:0')\n",
            "tensor(2478.3479, device='cuda:0')\n",
            "tensor(2558.1062, device='cuda:0')\n",
            "tensor(2486.6543, device='cuda:0')\n",
            "tensor(2454.1531, device='cuda:0')\n",
            "tensor(2541.4878, device='cuda:0')\n",
            "tensor(2489.0488, device='cuda:0')\n",
            "tensor(2546.2061, device='cuda:0')\n",
            "tensor(2513.1748, device='cuda:0')\n",
            "tensor(2527.2363, device='cuda:0')\n",
            "tensor(2530.6460, device='cuda:0')\n",
            "tensor(2514.3232, device='cuda:0')\n",
            "tensor(2544.8936, device='cuda:0')\n",
            "tensor(2499.7822, device='cuda:0')\n",
            "tensor(2578.1401, device='cuda:0')\n",
            "tensor(2521.3960, device='cuda:0')\n",
            "tensor(2492.3662, device='cuda:0')\n",
            "tensor(2479.0374, device='cuda:0')\n",
            "tensor(2549.5173, device='cuda:0')\n",
            "tensor(2471.8162, device='cuda:0')\n",
            "tensor(2507.0371, device='cuda:0')\n",
            "tensor(2555.5405, device='cuda:0')\n",
            "tensor(2548.5151, device='cuda:0')\n",
            "tensor(2468.5132, device='cuda:0')\n",
            "tensor(2482.4700, device='cuda:0')\n",
            "tensor(2577.4028, device='cuda:0')\n",
            "tensor(2524.8296, device='cuda:0')\n",
            "tensor(2487.0193, device='cuda:0')\n",
            "tensor(2546.0874, device='cuda:0')\n",
            "tensor(2479.2383, device='cuda:0')\n",
            "tensor(2536.6326, device='cuda:0')\n",
            "tensor(2526.5759, device='cuda:0')\n",
            "tensor(2510.6667, device='cuda:0')\n",
            "tensor(2494.0098, device='cuda:0')\n",
            "tensor(2486.6165, device='cuda:0')\n",
            "tensor(2521.1624, device='cuda:0')\n",
            "tensor(2521.8130, device='cuda:0')\n",
            "tensor(2488.8894, device='cuda:0')\n",
            "tensor(2540.9548, device='cuda:0')\n",
            "tensor(2521.0518, device='cuda:0')\n",
            "tensor(2539.9868, device='cuda:0')\n",
            "tensor(2555.3237, device='cuda:0')\n",
            "tensor(2531.7559, device='cuda:0')\n",
            "tensor(2511.4197, device='cuda:0')\n",
            "tensor(2552.8716, device='cuda:0')\n",
            "tensor(2585.4626, device='cuda:0')\n",
            "tensor(2531.2456, device='cuda:0')\n",
            "tensor(2532.0107, device='cuda:0')\n",
            "tensor(2518.2378, device='cuda:0')\n",
            "tensor(2509.5066, device='cuda:0')\n",
            "tensor(2501.5576, device='cuda:0')\n",
            "tensor(2481.2385, device='cuda:0')\n",
            "tensor(2510.1750, device='cuda:0')\n",
            "tensor(2496.0312, device='cuda:0')\n",
            "tensor(2533.5557, device='cuda:0')\n",
            "tensor(2512.2822, device='cuda:0')\n",
            "tensor(2501.2361, device='cuda:0')\n",
            "tensor(2477.9092, device='cuda:0')\n",
            "tensor(2556.9292, device='cuda:0')\n",
            "tensor(2525.9587, device='cuda:0')\n",
            "tensor(2526.3499, device='cuda:0')\n",
            "tensor(2511.5435, device='cuda:0')\n",
            "tensor(2583.3425, device='cuda:0')\n",
            "tensor(2518.5684, device='cuda:0')\n",
            "tensor(2494.8140, device='cuda:0')\n",
            "tensor(2511.9167, device='cuda:0')\n",
            "tensor(2500.3464, device='cuda:0')\n",
            "tensor(2542.6921, device='cuda:0')\n",
            "tensor(2488.3347, device='cuda:0')\n",
            "tensor(2546.5969, device='cuda:0')\n",
            "tensor(2475.7473, device='cuda:0')\n",
            "tensor(2481.7153, device='cuda:0')\n",
            "tensor(2485.2175, device='cuda:0')\n",
            "tensor(2602.8494, device='cuda:0')\n",
            "tensor(2479.4482, device='cuda:0')\n",
            "tensor(2474.3506, device='cuda:0')\n",
            "tensor(2521.8962, device='cuda:0')\n",
            "tensor(2571.8223, device='cuda:0')\n",
            "tensor(2521.5815, device='cuda:0')\n",
            "tensor(2488.4336, device='cuda:0')\n",
            "tensor(2524.1565, device='cuda:0')\n",
            "tensor(2516.3059, device='cuda:0')\n",
            "tensor(2479.5220, device='cuda:0')\n",
            "tensor(2524.1975, device='cuda:0')\n",
            "tensor(2494.8154, device='cuda:0')\n",
            "tensor(2518.7161, device='cuda:0')\n",
            "tensor(2518.3508, device='cuda:0')\n",
            "tensor(2511.3955, device='cuda:0')\n",
            "tensor(2514.8958, device='cuda:0')\n",
            "tensor(2477.1379, device='cuda:0')\n",
            "tensor(2516.2456, device='cuda:0')\n",
            "tensor(2511.8945, device='cuda:0')\n",
            "tensor(2554.5625, device='cuda:0')\n",
            "tensor(2533.5854, device='cuda:0')\n",
            "tensor(2547.0774, device='cuda:0')\n",
            "tensor(2491.3435, device='cuda:0')\n",
            "tensor(2474.5410, device='cuda:0')\n",
            "tensor(2514.1917, device='cuda:0')\n",
            "tensor(2535.7134, device='cuda:0')\n",
            "tensor(2591.2070, device='cuda:0')\n",
            "tensor(2494.0735, device='cuda:0')\n",
            "tensor(2473.1270, device='cuda:0')\n",
            "tensor(2550.4712, device='cuda:0')\n",
            "tensor(2587.2930, device='cuda:0')\n",
            "tensor(2593.4763, device='cuda:0')\n",
            "tensor(2576.2415, device='cuda:0')\n",
            "tensor(2520.8005, device='cuda:0')\n",
            "tensor(2507.4612, device='cuda:0')\n",
            "tensor(2566.3020, device='cuda:0')\n",
            "tensor(2463.0237, device='cuda:0')\n",
            "tensor(2563.7720, device='cuda:0')\n",
            "tensor(2507.0535, device='cuda:0')\n",
            "tensor(2552.3005, device='cuda:0')\n",
            "tensor(2573.4055, device='cuda:0')\n",
            "tensor(2487.6399, device='cuda:0')\n",
            "tensor(2520.9080, device='cuda:0')\n",
            "tensor(2538.9387, device='cuda:0')\n",
            "tensor(2500.2446, device='cuda:0')\n",
            "tensor(2544.8625, device='cuda:0')\n",
            "tensor(2497.9897, device='cuda:0')\n",
            "tensor(2505.2935, device='cuda:0')\n",
            "tensor(2557.8123, device='cuda:0')\n",
            "tensor(2490.9436, device='cuda:0')\n",
            "tensor(2479.0859, device='cuda:0')\n",
            "tensor(2472.9849, device='cuda:0')\n",
            "tensor(2540.5525, device='cuda:0')\n",
            "tensor(2574.0781, device='cuda:0')\n",
            "tensor(2574.6719, device='cuda:0')\n",
            "tensor(2529.6150, device='cuda:0')\n",
            "tensor(2537.9480, device='cuda:0')\n",
            "tensor(2548.3005, device='cuda:0')\n",
            "tensor(2470.7808, device='cuda:0')\n",
            "tensor(2511.7634, device='cuda:0')\n",
            "tensor(2583.6292, device='cuda:0')\n",
            "tensor(2562.4390, device='cuda:0')\n",
            "tensor(2553.7109, device='cuda:0')\n",
            "tensor(2497.7361, device='cuda:0')\n",
            "tensor(2459.6160, device='cuda:0')\n",
            "tensor(2541.9995, device='cuda:0')\n",
            "tensor(2551.5481, device='cuda:0')\n",
            "tensor(2538.3218, device='cuda:0')\n",
            "tensor(2503.8337, device='cuda:0')\n",
            "tensor(2531.2239, device='cuda:0')\n",
            "tensor(2557.2124, device='cuda:0')\n",
            "tensor(2538.2456, device='cuda:0')\n",
            "tensor(2550.0022, device='cuda:0')\n",
            "tensor(2538.9373, device='cuda:0')\n",
            "tensor(2536.4629, device='cuda:0')\n",
            "tensor(2514.2244, device='cuda:0')\n",
            "tensor(2540.1003, device='cuda:0')\n",
            "tensor(2534.8674, device='cuda:0')\n",
            "tensor(2495.2393, device='cuda:0')\n",
            "tensor(2519.4495, device='cuda:0')\n",
            "tensor(2546.6431, device='cuda:0')\n",
            "tensor(2552.0725, device='cuda:0')\n",
            "tensor(2496.8247, device='cuda:0')\n",
            "tensor(2559.4778, device='cuda:0')\n",
            "tensor(2546.2710, device='cuda:0')\n",
            "tensor(2560.3110, device='cuda:0')\n",
            "tensor(2530.7839, device='cuda:0')\n",
            "tensor(2520.1011, device='cuda:0')\n",
            "tensor(2524.0942, device='cuda:0')\n",
            "tensor(2470.6990, device='cuda:0')\n",
            "tensor(2464.0625, device='cuda:0')\n",
            "tensor(2551.5920, device='cuda:0')\n",
            "tensor(2466.8789, device='cuda:0')\n",
            "tensor(2505.0286, device='cuda:0')\n",
            "tensor(2525.4246, device='cuda:0')\n",
            "tensor(2539.3054, device='cuda:0')\n",
            "tensor(2507.7952, device='cuda:0')\n",
            "tensor(2593.0413, device='cuda:0')\n",
            "tensor(2514.5181, device='cuda:0')\n",
            "tensor(2539.6719, device='cuda:0')\n",
            "tensor(2539.1885, device='cuda:0')\n",
            "tensor(2498.0349, device='cuda:0')\n",
            "tensor(2543.9453, device='cuda:0')\n",
            "tensor(2517.3032, device='cuda:0')\n",
            "tensor(2486.2825, device='cuda:0')\n",
            "tensor(2542.8279, device='cuda:0')\n",
            "tensor(2519.5083, device='cuda:0')\n",
            "tensor(2504.6377, device='cuda:0')\n",
            "tensor(2559.1780, device='cuda:0')\n",
            "tensor(2470.0151, device='cuda:0')\n",
            "tensor(2573.4380, device='cuda:0')\n",
            "tensor(2546.7795, device='cuda:0')\n",
            "tensor(2547.3147, device='cuda:0')\n",
            "tensor(2542.5437, device='cuda:0')\n",
            "tensor(2490.6709, device='cuda:0')\n",
            "tensor(2532.2285, device='cuda:0')\n",
            "tensor(2529.3135, device='cuda:0')\n",
            "tensor(2477.7979, device='cuda:0')\n",
            "tensor(2543.3792, device='cuda:0')\n",
            "tensor(2540.2607, device='cuda:0')\n",
            "tensor(2500.0488, device='cuda:0')\n",
            "tensor(2530.8970, device='cuda:0')\n",
            "tensor(2489.7651, device='cuda:0')\n",
            "tensor(2521.4231, device='cuda:0')\n",
            "tensor(2561.7524, device='cuda:0')\n",
            "tensor(2509.1853, device='cuda:0')\n",
            "tensor(2541.5376, device='cuda:0')\n",
            "tensor(2513.7356, device='cuda:0')\n",
            "tensor(2501.1492, device='cuda:0')\n",
            "tensor(2483.2175, device='cuda:0')\n",
            "tensor(2570.0676, device='cuda:0')\n",
            "tensor(2536.2800, device='cuda:0')\n",
            "tensor(2540.8699, device='cuda:0')\n",
            "tensor(2525.0989, device='cuda:0')\n",
            "tensor(2476.9116, device='cuda:0')\n",
            "tensor(2489.6548, device='cuda:0')\n",
            "tensor(2514.3445, device='cuda:0')\n",
            "tensor(2523.9639, device='cuda:0')\n",
            "tensor(2493.3943, device='cuda:0')\n",
            "tensor(2484.9634, device='cuda:0')\n",
            "tensor(2525.5515, device='cuda:0')\n",
            "tensor(2514.5146, device='cuda:0')\n",
            "tensor(2520.2261, device='cuda:0')\n",
            "tensor(2524.3147, device='cuda:0')\n",
            "tensor(2509.4812, device='cuda:0')\n",
            "tensor(2596.2158, device='cuda:0')\n",
            "tensor(2518.7070, device='cuda:0')\n",
            "tensor(2488.5750, device='cuda:0')\n",
            "tensor(2549.7058, device='cuda:0')\n",
            "tensor(2509.3953, device='cuda:0')\n",
            "tensor(2548.8308, device='cuda:0')\n",
            "tensor(2483.1401, device='cuda:0')\n",
            "tensor(2498.4226, device='cuda:0')\n",
            "tensor(2549.8606, device='cuda:0')\n",
            "tensor(2521.0376, device='cuda:0')\n",
            "tensor(2546.8591, device='cuda:0')\n",
            "tensor(2505.8608, device='cuda:0')\n",
            "tensor(2510.6011, device='cuda:0')\n",
            "tensor(2530.3818, device='cuda:0')\n",
            "tensor(2522.6465, device='cuda:0')\n",
            "tensor(2507.3850, device='cuda:0')\n",
            "tensor(2508.6289, device='cuda:0')\n",
            "tensor(2536.9741, device='cuda:0')\n",
            "tensor(2485.5613, device='cuda:0')\n",
            "tensor(2518.9263, device='cuda:0')\n",
            "tensor(2533.9692, device='cuda:0')\n",
            "tensor(2523.9009, device='cuda:0')\n",
            "tensor(2509.1057, device='cuda:0')\n",
            "tensor(2516.1177, device='cuda:0')\n",
            "tensor(2533.6147, device='cuda:0')\n",
            "tensor(2550.6067, device='cuda:0')\n",
            "tensor(2511.1218, device='cuda:0')\n",
            "tensor(2477.7544, device='cuda:0')\n",
            "tensor(2542.5254, device='cuda:0')\n",
            "tensor(2484.7429, device='cuda:0')\n",
            "tensor(2512.2627, device='cuda:0')\n",
            "tensor(2503.7415, device='cuda:0')\n",
            "tensor(2503.2427, device='cuda:0')\n",
            "tensor(2513.6033, device='cuda:0')\n",
            "tensor(2518.8601, device='cuda:0')\n",
            "tensor(2532.4834, device='cuda:0')\n",
            "tensor(2513.9297, device='cuda:0')\n",
            "tensor(2510.4207, device='cuda:0')\n",
            "tensor(2520.6523, device='cuda:0')\n",
            "tensor(2518.2896, device='cuda:0')\n",
            "tensor(2548.5845, device='cuda:0')\n",
            "tensor(2523.4971, device='cuda:0')\n",
            "tensor(2502.1965, device='cuda:0')\n",
            "tensor(2486.4436, device='cuda:0')\n",
            "tensor(2510.9644, device='cuda:0')\n",
            "tensor(2505.2358, device='cuda:0')\n",
            "tensor(2520.8530, device='cuda:0')\n",
            "tensor(2487.1804, device='cuda:0')\n",
            "tensor(2517.9614, device='cuda:0')\n",
            "tensor(2507.4131, device='cuda:0')\n",
            "tensor(2548.7141, device='cuda:0')\n",
            "tensor(2550.6084, device='cuda:0')\n",
            "tensor(2567.3049, device='cuda:0')\n",
            "tensor(2545.4158, device='cuda:0')\n",
            "tensor(2463.0369, device='cuda:0')\n",
            "tensor(2490.1624, device='cuda:0')\n",
            "tensor(2536.6016, device='cuda:0')\n",
            "tensor(2552.9458, device='cuda:0')\n",
            "tensor(2511.7805, device='cuda:0')\n",
            "tensor(2470.8672, device='cuda:0')\n",
            "tensor(2533.9465, device='cuda:0')\n",
            "tensor(2510.9612, device='cuda:0')\n",
            "tensor(2467.5869, device='cuda:0')\n",
            "tensor(2524.2600, device='cuda:0')\n",
            "tensor(2564.0295, device='cuda:0')\n",
            "tensor(2531.0034, device='cuda:0')\n",
            "tensor(2455.9871, device='cuda:0')\n",
            "tensor(2536.6802, device='cuda:0')\n",
            "tensor(2479.0425, device='cuda:0')\n",
            "tensor(2540.7778, device='cuda:0')\n",
            "tensor(2567.4792, device='cuda:0')\n",
            "tensor(2513.0432, device='cuda:0')\n",
            "tensor(2530.9021, device='cuda:0')\n",
            "tensor(2553.2612, device='cuda:0')\n",
            "tensor(2560.7354, device='cuda:0')\n",
            "tensor(2518.2053, device='cuda:0')\n",
            "tensor(2507.7903, device='cuda:0')\n",
            "tensor(2502.7109, device='cuda:0')\n",
            "tensor(2504.9985, device='cuda:0')\n",
            "tensor(2521.1997, device='cuda:0')\n",
            "tensor(2522.4929, device='cuda:0')\n",
            "tensor(2515.0955, device='cuda:0')\n",
            "tensor(2557.0383, device='cuda:0')\n",
            "tensor(2562.2300, device='cuda:0')\n",
            "tensor(2529.3298, device='cuda:0')\n",
            "tensor(2498.5986, device='cuda:0')\n",
            "tensor(2507.4873, device='cuda:0')\n",
            "tensor(2466.9075, device='cuda:0')\n",
            "tensor(2516.7654, device='cuda:0')\n",
            "tensor(2534.7012, device='cuda:0')\n",
            "tensor(2550.3088, device='cuda:0')\n",
            "tensor(2480.1777, device='cuda:0')\n",
            "tensor(2500.5496, device='cuda:0')\n",
            "tensor(2496.4407, device='cuda:0')\n",
            "tensor(2542.4839, device='cuda:0')\n",
            "tensor(2497.5569, device='cuda:0')\n",
            "tensor(2511.4541, device='cuda:0')\n",
            "tensor(2488.3369, device='cuda:0')\n",
            "tensor(2535.5757, device='cuda:0')\n",
            "tensor(2520.3630, device='cuda:0')\n",
            "tensor(2539.9685, device='cuda:0')\n",
            "tensor(2534.5588, device='cuda:0')\n",
            "tensor(2501.8936, device='cuda:0')\n",
            "tensor(2541.7080, device='cuda:0')\n",
            "tensor(2548.1384, device='cuda:0')\n",
            "tensor(2509.1851, device='cuda:0')\n",
            "tensor(2512.7319, device='cuda:0')\n",
            "tensor(2516.3948, device='cuda:0')\n",
            "tensor(2515.2627, device='cuda:0')\n",
            "tensor(2521.5100, device='cuda:0')\n",
            "tensor(2523.0356, device='cuda:0')\n",
            "tensor(2573.3677, device='cuda:0')\n",
            "tensor(2476.8711, device='cuda:0')\n",
            "tensor(2526.6846, device='cuda:0')\n",
            "tensor(2487.0017, device='cuda:0')\n",
            "tensor(2435.8071, device='cuda:0')\n",
            "tensor(2493.9966, device='cuda:0')\n",
            "tensor(2549.3967, device='cuda:0')\n",
            "tensor(2511.1606, device='cuda:0')\n",
            "tensor(2536.3132, device='cuda:0')\n",
            "tensor(2509.1184, device='cuda:0')\n",
            "tensor(2529.2058, device='cuda:0')\n",
            "tensor(2502.5205, device='cuda:0')\n",
            "tensor(2488.4556, device='cuda:0')\n",
            "tensor(2536.0559, device='cuda:0')\n",
            "tensor(2549.0989, device='cuda:0')\n",
            "tensor(2525.1409, device='cuda:0')\n",
            "tensor(2490.0422, device='cuda:0')\n",
            "tensor(2562.2808, device='cuda:0')\n",
            "tensor(2516.7468, device='cuda:0')\n",
            "tensor(2509.2966, device='cuda:0')\n",
            "tensor(2551.8125, device='cuda:0')\n",
            "tensor(2521.3940, device='cuda:0')\n",
            "tensor(2489.2971, device='cuda:0')\n",
            "tensor(2537.3428, device='cuda:0')\n",
            "tensor(2517.6426, device='cuda:0')\n",
            "tensor(2524.7847, device='cuda:0')\n",
            "tensor(2525.0852, device='cuda:0')\n",
            "tensor(2460.6482, device='cuda:0')\n",
            "tensor(2478.1587, device='cuda:0')\n",
            "tensor(2528.5103, device='cuda:0')\n",
            "tensor(2541.3196, device='cuda:0')\n",
            "tensor(2536.0737, device='cuda:0')\n",
            "tensor(2530.7605, device='cuda:0')\n",
            "tensor(2515.5105, device='cuda:0')\n",
            "tensor(2464.7073, device='cuda:0')\n",
            "tensor(2574.0833, device='cuda:0')\n",
            "tensor(2523.4348, device='cuda:0')\n",
            "tensor(2498.9180, device='cuda:0')\n",
            "tensor(2529.2625, device='cuda:0')\n",
            "tensor(2538.9780, device='cuda:0')\n",
            "tensor(2481.3408, device='cuda:0')\n",
            "tensor(2509.7080, device='cuda:0')\n",
            "tensor(2569.3594, device='cuda:0')\n",
            "tensor(2471.3074, device='cuda:0')\n",
            "tensor(2532.8005, device='cuda:0')\n",
            "tensor(2508.6919, device='cuda:0')\n",
            "tensor(2565.9883, device='cuda:0')\n",
            "tensor(2516.8752, device='cuda:0')\n",
            "tensor(2475.5461, device='cuda:0')\n",
            "tensor(2573.0952, device='cuda:0')\n",
            "tensor(2622.2783, device='cuda:0')\n",
            "tensor(2542.3062, device='cuda:0')\n",
            "tensor(2503.9700, device='cuda:0')\n",
            "tensor(2571.9609, device='cuda:0')\n",
            "tensor(2495.6538, device='cuda:0')\n",
            "tensor(2525.5945, device='cuda:0')\n",
            "tensor(2492.4915, device='cuda:0')\n",
            "tensor(2471.1802, device='cuda:0')\n",
            "tensor(2524.5212, device='cuda:0')\n",
            "tensor(2533.5481, device='cuda:0')\n",
            "tensor(2555.8030, device='cuda:0')\n",
            "tensor(2517.2212, device='cuda:0')\n",
            "tensor(2511.6777, device='cuda:0')\n",
            "tensor(2581.1484, device='cuda:0')\n",
            "tensor(2517.0654, device='cuda:0')\n",
            "tensor(2522.0674, device='cuda:0')\n",
            "tensor(2544.4751, device='cuda:0')\n",
            "tensor(2432.5513, device='cuda:0')\n",
            "tensor(2514.5815, device='cuda:0')\n",
            "tensor(2491.0076, device='cuda:0')\n",
            "tensor(2515.5444, device='cuda:0')\n",
            "tensor(2551.2539, device='cuda:0')\n",
            "tensor(2587.4424, device='cuda:0')\n",
            "tensor(2535.1038, device='cuda:0')\n",
            "tensor(2516.3801, device='cuda:0')\n",
            "tensor(2507.7607, device='cuda:0')\n",
            "tensor(2508.9832, device='cuda:0')\n",
            "tensor(2534.9412, device='cuda:0')\n",
            "tensor(2585.6799, device='cuda:0')\n",
            "tensor(2513.3503, device='cuda:0')\n",
            "tensor(2493.0686, device='cuda:0')\n",
            "tensor(2523.8687, device='cuda:0')\n",
            "tensor(2520.9775, device='cuda:0')\n",
            "tensor(2513.3799, device='cuda:0')\n",
            "tensor(2542.7051, device='cuda:0')\n",
            "tensor(2539.1042, device='cuda:0')\n",
            "tensor(2484.8474, device='cuda:0')\n",
            "tensor(2534.4509, device='cuda:0')\n",
            "tensor(2507.1311, device='cuda:0')\n",
            "tensor(2509.0522, device='cuda:0')\n",
            "tensor(2517.3887, device='cuda:0')\n",
            "tensor(2474.3259, device='cuda:0')\n",
            "tensor(2505.8772, device='cuda:0')\n",
            "tensor(2503.9773, device='cuda:0')\n",
            "tensor(2480.4944, device='cuda:0')\n",
            "tensor(2494.4204, device='cuda:0')\n",
            "tensor(2492.9905, device='cuda:0')\n",
            "tensor(2534.7629, device='cuda:0')\n",
            "tensor(2472.1155, device='cuda:0')\n",
            "tensor(2533.5251, device='cuda:0')\n",
            "tensor(2494.0559, device='cuda:0')\n",
            "tensor(2493.8733, device='cuda:0')\n",
            "tensor(2511.9246, device='cuda:0')\n",
            "tensor(2498.2339, device='cuda:0')\n",
            "tensor(2502.1262, device='cuda:0')\n",
            "tensor(2553.3909, device='cuda:0')\n",
            "tensor(2554.8508, device='cuda:0')\n",
            "tensor(2564.6328, device='cuda:0')\n",
            "tensor(2486.3604, device='cuda:0')\n",
            "tensor(2513.1777, device='cuda:0')\n",
            "tensor(2540.7449, device='cuda:0')\n",
            "tensor(2511.9673, device='cuda:0')\n",
            "tensor(2502.9197, device='cuda:0')\n",
            "tensor(2522.8997, device='cuda:0')\n",
            "tensor(2571.6257, device='cuda:0')\n",
            "tensor(2507.3984, device='cuda:0')\n",
            "tensor(2506.2024, device='cuda:0')\n",
            "tensor(2511.9399, device='cuda:0')\n",
            "tensor(2531.5881, device='cuda:0')\n",
            "tensor(2534.0146, device='cuda:0')\n",
            "tensor(2539.8813, device='cuda:0')\n",
            "tensor(2512.1719, device='cuda:0')\n",
            "tensor(2511.3469, device='cuda:0')\n",
            "tensor(2483.0559, device='cuda:0')\n",
            "tensor(2496.6448, device='cuda:0')\n",
            "tensor(2538.9360, device='cuda:0')\n",
            "tensor(2584.4929, device='cuda:0')\n",
            "tensor(2480.4990, device='cuda:0')\n",
            "tensor(2504.7405, device='cuda:0')\n",
            "tensor(2563.5305, device='cuda:0')\n",
            "tensor(2558.9917, device='cuda:0')\n",
            "tensor(2535.1370, device='cuda:0')\n",
            "tensor(2528.2974, device='cuda:0')\n",
            "tensor(2506.0027, device='cuda:0')\n",
            "tensor(2476.6228, device='cuda:0')\n",
            "tensor(2485.8022, device='cuda:0')\n",
            "tensor(2526.7170, device='cuda:0')\n",
            "tensor(2512.1318, device='cuda:0')\n",
            "tensor(2528.9739, device='cuda:0')\n",
            "tensor(2473.1445, device='cuda:0')\n",
            "tensor(2563.3621, device='cuda:0')\n",
            "tensor(2486.5137, device='cuda:0')\n",
            "tensor(2525.9658, device='cuda:0')\n",
            "tensor(2486.3533, device='cuda:0')\n",
            "tensor(2522.0642, device='cuda:0')\n",
            "tensor(2523.2178, device='cuda:0')\n",
            "tensor(2525.9519, device='cuda:0')\n",
            "tensor(2520.4419, device='cuda:0')\n",
            "tensor(2524.1721, device='cuda:0')\n",
            "tensor(2552.6104, device='cuda:0')\n",
            "tensor(2534.0339, device='cuda:0')\n",
            "tensor(2534.5679, device='cuda:0')\n",
            "tensor(2563.4277, device='cuda:0')\n",
            "tensor(2523.6980, device='cuda:0')\n",
            "tensor(2534.5503, device='cuda:0')\n",
            "tensor(2525.8123, device='cuda:0')\n",
            "tensor(2535.8137, device='cuda:0')\n",
            "tensor(2512.4351, device='cuda:0')\n",
            "tensor(2499.3337, device='cuda:0')\n",
            "tensor(2515.1211, device='cuda:0')\n",
            "tensor(2561.6555, device='cuda:0')\n",
            "tensor(2514.9321, device='cuda:0')\n",
            "tensor(2498.6550, device='cuda:0')\n",
            "tensor(2481.5415, device='cuda:0')\n",
            "tensor(2506.2290, device='cuda:0')\n",
            "tensor(2516.0547, device='cuda:0')\n",
            "tensor(2533.2246, device='cuda:0')\n",
            "tensor(2513.7600, device='cuda:0')\n",
            "tensor(2537.1562, device='cuda:0')\n",
            "tensor(2531.7722, device='cuda:0')\n",
            "tensor(2527.7827, device='cuda:0')\n",
            "tensor(2568.2791, device='cuda:0')\n",
            "tensor(2475.5996, device='cuda:0')\n",
            "tensor(2566.9219, device='cuda:0')\n",
            "tensor(2564.2378, device='cuda:0')\n",
            "tensor(2501.0200, device='cuda:0')\n",
            "tensor(2535.7869, device='cuda:0')\n",
            "tensor(2526.2898, device='cuda:0')\n",
            "tensor(2595.4250, device='cuda:0')\n",
            "tensor(2493.7612, device='cuda:0')\n",
            "tensor(2518.1711, device='cuda:0')\n",
            "tensor(2514.6348, device='cuda:0')\n",
            "tensor(2539.9421, device='cuda:0')\n",
            "tensor(2530.4080, device='cuda:0')\n",
            "tensor(2538.3865, device='cuda:0')\n",
            "tensor(2516.4805, device='cuda:0')\n",
            "tensor(2538.2959, device='cuda:0')\n",
            "tensor(2525.2961, device='cuda:0')\n",
            "tensor(2540.7666, device='cuda:0')\n",
            "tensor(2518.4067, device='cuda:0')\n",
            "tensor(2487.2910, device='cuda:0')\n",
            "tensor(2510.0886, device='cuda:0')\n",
            "tensor(2537.4946, device='cuda:0')\n",
            "tensor(2524.6245, device='cuda:0')\n",
            "tensor(2510.2661, device='cuda:0')\n",
            "tensor(2548.4885, device='cuda:0')\n",
            "tensor(2513.9807, device='cuda:0')\n",
            "tensor(2550.4585, device='cuda:0')\n",
            "tensor(2611.0581, device='cuda:0')\n",
            "tensor(2529.2026, device='cuda:0')\n",
            "tensor(2573.6362, device='cuda:0')\n",
            "tensor(2560.8455, device='cuda:0')\n",
            "tensor(2547.0081, device='cuda:0')\n",
            "tensor(2555.7307, device='cuda:0')\n",
            "tensor(2490.5403, device='cuda:0')\n",
            "tensor(2470.9937, device='cuda:0')\n",
            "tensor(2533.3013, device='cuda:0')\n",
            "tensor(2509.7498, device='cuda:0')\n",
            "tensor(2561.2424, device='cuda:0')\n",
            "tensor(2502.4336, device='cuda:0')\n",
            "tensor(2467.6958, device='cuda:0')\n",
            "tensor(2490.3643, device='cuda:0')\n",
            "tensor(2503.7356, device='cuda:0')\n",
            "tensor(2549.6257, device='cuda:0')\n",
            "tensor(2512.1580, device='cuda:0')\n",
            "实验一消耗时间：0.23122763633728027，  实验二消耗时间：1.7139215469360352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.测量同时在两个GPU上执行两个矩阵乘法与在一个GPU上按顺序执行两个矩阵乘法所需的时间。提示：应该看到近乎线性的缩放"
      ],
      "metadata": {
        "id": "PdGDK0Sh4e_L"
      },
      "id": "PdGDK0Sh4e_L"
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "oZ004qEb4eq4"
      },
      "id": "oZ004qEb4eq4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0460f3be",
      "metadata": {
        "origin_pos": 64,
        "tab": [
          "pytorch"
        ],
        "id": "0460f3be"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/1841)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}